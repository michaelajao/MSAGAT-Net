\section{Related Work}

\subsection{Spatio-Temporal GNNs for Epidemic Forecasting}
Graph-based models have gained traction in epidemic forecasting. The **Cola-GNN** introduces cross-location attention for long-horizon ILI prediction, enhancing inter-regional influence modeling \cite{Deng2019}. The **STAN** model uses spatio-temporal attention networks, integrated with epidemiological laws, to predict COVID-19 cases with strong short- and long-term performance \cite{Gao2020}. More recent works include **GAST**, a graph-attention spatio-temporal model applied to both influenza and COVID-19 datasets \cite{Zhu2024}, and **MSGNN**, which explicitly learns multi-scale graphs capturing long-range connections and mining scale-shared versus scale-specific patterns \cite{Qiu2023}. **EpiGNN** uses learned spatial transmission risk and mobility data to forecast regional epidemics \cite{EpiGNN2022}. **DASTGNN** introduces time-varying adaptive attention mechanisms to account for dynamics in COVID-19 data \cite{DASTGNN2023}. A Dutch municipal-level case study applies GATv2 within ST-GNNs to understand regional spread patterns \cite{Frontiers2023}.

\subsection{Efficient / Linear-Time Attention}
Traditional attention mechanisms scale quadratically with sequence length or number of nodes. To address this, methods like **Linformer** reduce complexity via low-rank approximations \cite{Wang2020}, while **Performer** (FAVOR+) uses random feature methods for linearized attention. **Linear Transformers** and **Nyströmformer** employ kernel methods and landmark-based approximations to maintain \(O(n)\) complexity.

\subsection{Graph GNN Baselines}
Common ST-GNN baselines include **DCRNN** (diffusive graph convolution with encoder-decoder), **STGCN** (spatio-temporal convolution blocks), **Graph WaveNet** (adaptive adjacency + dilated TCN), and **AGCRN** (node-adaptive parameter learning)—all foundational architectures in spatiotemporal modeling \cite{Li2018, Yu2018, Wu2019, Bai2020}.

\subsection{Mechanistic and Epidemiology-Informed Models}
Models such as **CausalGNN** integrate epidemiological compartmental dynamics (e.g., SIRD models) into attention-based GNNs to capture causal transmission mechanisms and enhance forecasting robustness \cite{Wang2022}. **MPSTAN** leverages multi-patch epidemiological knowledge through attention networks to model inter-patch interactions more effectively \cite{Mao2024}. **HeatGNN** introduces epidemiology-informed embeddings to reflect mechanistic heterogeneity across locations, allowing dynamic transmission graphs to vary across time and geography \cite{Zheng2024}.

\subsection{Positioning of MSAGAT-Net}
MSAGAT-Net bridges gaps in existing approaches by combining:
\begin{itemize}
  \item \textbf{Linear-time attention (EAGAM)} for efficiency in dense inter-regional modeling.
  \item \textbf{Dilated multi-scale temporal modeling (DMTM)}, capturing both short- and long-term epidemic patterns.
  \item \textbf{Progressive multi-horizon forecasting (PPM)} for iterative prediction.
\end{itemize}
This combination distinguishes MSAGAT-Net from prior models like Cola-GNN, GAST, MSGNN, and others—by emphasizing computational efficiency, temporal multi-scale dynamics, and practical interpretability, all supported through rigorous ablation studies and performance analysis.

% BibTeX Entries:

\bibliographystyle{plain}
\bibliography{msagat_related_work}

% Sample BibTeX items:
@inproceedings{Deng2019,
  title={Graph Message Passing with Cross-location Attentions for Long-term ILI Prediction},
  author={Deng, Songgaojun and others},
  year={2019},
  note={arXiv 1912.10202}
}
@article{Gao2020,
  title={STAN: Spatio-Temporal Attention Network for Pandemic Prediction Using Real World Evidence},
  author={Gao, Junyi and others},
  year={2020},
  note={arXiv 2008.04215}
}
@article{Zhu2024,
  title={Modeling epidemic dynamics using Graph Attention based Spatial Temporal networks},
  author={Zhu, Xiaofeng and others},
  year={2024},
  journal={PLOS ONE}
}
@article{Qiu2023,
  title={MSGNN: Multi-scale Spatio-temporal Graph Neural Network},
  author={Qiu, M. and others},
  year={2023},
  note={arXiv 2308.15840}
}
@article{EpiGNN2022,
  title={EpiGNN: Exploring Spatial Transmission with Graph Neural Network for Regional Epidemic Forecasting},
  author={Unnamed},
  year={2022},
  note={arXiv 2208.11517}
}
@article{DASTGNN2023,
  title={Dynamic Adaptive Spatio-Temporal Graph Network for COVID-19 Forecasting},
  author={Unnamed},
  year={2023},
  note={DASTGNN}
}
@article{Frontiers2023,
  title={ST-GNN for Dutch municipalities using GATv2},
  author={Unnamed},
  year={2023},
  journal={Frontiers in Physics}
}
@article{Wang2020,
  title={Linformer: Self-Attention with Linear Complexity},
  author={Wang, Sinong and others},
  year={2020},
  note={arXiv 2006.04768}
}
@inproceedings{Li2018,
  title={Diffusion Convolutional Recurrent Neural Network: Data-driven Traffic Forecasting},
  author={Li, Y. and others},
  year={2018},
  note={arXiv 1707.01926}
}
@inproceedings{Yu2018,
  title={Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting},
  author={Yu, B. and others},
  year={2018},
  note={IJCAI}
}
@article{Wu2019,
  title={Graph WaveNet for Deep Spatial-Temporal Graph Modeling},
  author={Wu, Z. and others},
  year={2019},
  note={arXiv 1906.00121}
}
@inproceedings{Bai2020,
  title={Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting},
  author={Bai, L. and others},
  year={2020},
  note={NeurIPS}
}
@inproceedings{Wang2022,
  title={CausalGNN: Causal-based Graph Neural Networks for Spatio-Temporal Embedding},
  author={Wang, L. and others},
  year={2022},
  note={AAAI}
}
@article{Mao2024,
  title={MPSTAN: Metapopulation-Based Spatio-Temporal Attention Network},
  author={Mao, J. and others},
  year={2024},
  journal={Entropy}
}
@article{Zheng2024,
  title={Epidemiology-informed Graph Neural Network for Heterogeneity-aware Epidemic Forecasting},
  author={Zheng, Y. and others},
  year={2024},
  note={arXiv 2411.17372}
}

% \subsection{Traditional Epidemic Modeling}
% Classical approaches to epidemic modeling rely on compartmental models such as SIR (Susceptible-Infected-Recovered) and its variants. While these models provide interpretable parameters and theoretical guarantees, they often fail to capture complex spatial dependencies and require extensive domain expertise for parameter estimation. Recent extensions have incorporated spatial components, but computational complexity remains a significant challenge for large-scale applications.

% \subsection{Deep Learning for Time Series Forecasting}
% Recurrent Neural Networks (RNNs) and their variants (LSTM, GRU) have been widely applied to epidemic forecasting. However, these models struggle with long-range dependencies and do not naturally incorporate spatial relationships. Transformer-based models have shown promise but suffer from quadratic complexity in the sequence length, limiting their applicability to large-scale spatiotemporal problems.

% \subsection{Graph Neural Networks for Spatiotemporal Modeling}
% Recent advances in Graph Neural Networks (GNNs) have enabled explicit modeling of spatial dependencies. Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs) have been applied to traffic forecasting and weather prediction with promising results. However, existing approaches often face scalability issues due to the computational cost of message passing, particularly for dense graphs representing epidemic spread patterns.

% \subsection{Multi-Scale Temporal Processing}
% The importance of multi-scale analysis in time series forecasting has been recognized in various domains. Dilated convolutions and wavelet transforms have been employed to capture patterns at different temporal resolutions. However, existing methods often use fixed-scale decompositions that may not adapt to the varying dynamics of epidemic spread.


% ---------- SECTION II: LITERATURE REVIEW ----------
\section{Related Work}

Early epidemiological forecasting relied on compartmental models (e.g. SIR, SEIR) and statistical time-series methods, which often struggle to capture complex spatial interactions and non-linear trends \citep{lijingwangCausalGNNCausalBasedGraph2022}. In recent years, deep learning approaches have gained prominence for epidemic modeling In particular, graph neural networks (GNNs) have emerged as powerful tools to model disease spread across interconnected regions, as they naturally represent locations as nodes and interactions (e.g. travel, proximity) as edges. GNN-based models address limitations of traditional models’ oversimplified assumptions by learning complex spatiotemporal relations directly from data. A recent survey by \citet{liuReviewGraphNeural2024a} categorizes these methods into pure neural vs. hybrid mechanistic+neural models, highlighting their growing importance in epidemiology

One of the first works to apply GNNs for disease prediction was Cola-GNN by \citet{dengColaGNNCrosslocationAttention2020a } which introduced a dynamic \textit{cross-location attention} mechanism for long-term influenza forecasting, Instead of using a fixed geographic adjacency, Cola-GNN learns an attention weight matrix between regions that serves as an adaptive graph, capturing time-varying influences between locations. This graph attention is coupled with a temporal module (dilated CNNs) to extract short- and long-term patterns yielding improved multi-week ILI predictions and interpretable insights (e.g. which regions influence others) Building on such ideas, \citet{xie2022epignn} proposed EpiGNN, which designs a \textit{transmission risk encoding} and a Region-Aware Graph Learner to incorporate both local and global spatial effects. EpiGNN can integrate external data like human mobility into the graph learning process, making each region “aware” of other regions’ situations . This approach outperformed prior state-of-the-art by about 9.5\% in RMSE on influenza and COVID-19 datasets, demonstrating the benefit of adaptive graphs. Similarly, STAN (Spatio-Temporal Attention Network) proposed by \citet{gao2021stan} leveraged an attention-based graph convolution to capture dynamic geographical influences for COVID-19 forecasts, By incorporating patient EHR features and a geography-based attention mechanism, STAN could learn the spatial-temporal trends across all U.S. counties, significantly outperforming classic SIR/SEIR models (up to 87\% lower MSE). Notably, STAN also added a regularization term based on pandemic physics (compartmental dynamics) to improve long-range stability.

These works underscore how attention-enhanced GNNs can better model disease spread than models with static or hand-crafted adjacency. In fact, using a fixed graph (e.g. just nearest-neighbor regions) may misrepresent true infection pathways. Some methods therefore entirely learn the graph from data, such as correlating historical case trajectories but this can ignore known geographic or demographic ties. Modern approaches tend to combine data-driven and knowledge-driven connectivity, using multi-source information to define graphs flexibly For instance, \citet{gao2023evidence} note that purely manual graphs or purely learned graphs are suboptimal, and they leverage both types of information in their design.

Modeling the temporal dimension is as crucial as the spatial. Epidemic time series often exhibit complex seasonality, trends, and behavioral change effects. Deep learning models handle multi-step forecasting either by direct methods (predicting multiple weeks in one go) or iterative methods (one step at a time) Direct multi-horizon models (e.g. some seq2seq LSTM or CNN-based models) have shown good performance in flu forecasting but can require large training data and often rely on external covariates Iterative strategies, on the other hand, risk error accumulation over long horizons. Recent works try to mitigate these issues, such as \citet{dengColaGNNCrosslocationAttention2020a} Cola-GNN addressed long-term forecasting by extracting multi-scale temporal features (through dilated convolutions) and found that incorporating seasonal trends helped stability. Other researchers have proposed hybrid approaches, such as \citet{wu2018deep} and \citet{venna2019novel} explored direct long-term neural predictors for influenza, while a model called DEFSI from \citet{wang2019defsi} and STAN combined deep learning with a compartmental model to improve long-range forecasts for flu and COVID-19 respectively. These approaches often leverage external data (climate, demographics, Google search trends) to inform long-range forecasts. The importance of capturing both short-term outbreaks and long-term waves has also led to multi-module architectures. Our proposed MSAGAT-Net follows this trend by using a \textit{Dilated Multi-Scale Temporal Module} to simultaneously capture high-frequency fluctuations (e.g. weekly spikes) and low-frequency trends (seasonal or yearly) in the epidemic time series, similar in spirit to Cola-GNN’s temporal convolution module. Furthermore, to produce stable multi-week forecasts, iterative prediction frameworks with refinement (as in our Progressive Prediction Module) are often employed, echoing the iterative strategies discussed in prior works

A major line of recent research integrates epidemiological domain knowledge into deep learning models to improve interpretability and performance. For example, \citet{lijingwangCausalGNNCausalBasedGraph2022} proposed CausalGNN, which combines a mechanistic ODE-based disease model with a dynamic GNN. In CausalGNN, an attention-based GNN module captures cross-region influences, while a \emph{causal module} based on an SIR-type ODE injects epidemiological context into the node embeddings This mutually-informed design yields more robust predictions with fewer parameters, since the mechanistic component guides the learning of latent representations. Another example is MepoGNN by \citet{cao2022mepognn}, which uses a multi-patch SEIR model a “metapopulation” GNN approach. MepoGNN merges a multi-patch compartmental model (a network of region-level SEIR simulators) with a Graph Attention Network that ingests real-world mobility and case data Essentially, the GAT in MepoGNN turns static travel matrices into dynamic transmission adjacency matrices by analyzing time-varying patterns in each city’s data This helped predict COVID-19 spread in South Korea more accurately than pure simulation models, and notably the learned transmission rates aligned well with actual policy interventions like social distancing mandates. \citet{gao2023evidence} took a physics-inspired approach with their HOIST model, drawing an analogy between disease spread and an Ising spin system They treated counties as nodes on a lattice and used Ising dynamics to regularize a deep forecasting model, thereby encoding the idea that neighboring regions’ case counts should evolve in correlated ways HOIST was evaluated on 2,299 US counties for 4-week COVID-19 hospitalization forecasting, using rich multimodal features (medical claims, census data, hospital capacity) It achieved high accuracy (e.g. $R^2=0.6$, 0.89 correlation) and provided valuable insights for instance, analysis of its learned parameters suggested that increasing rural vaccinations would yield the most improvement in outcomes, a non-intuitive policy insight
These examples show that marrying mechanistic models with neural networks can improve generalization in data-scarce scenarios (like new pandemics) and lend interpretability to deep forecasts. A recent Scientific Reports study in 2022 also combined spatio-temporal statistical models with GNNs for COVID-19 in Germany their framework \citet{fritz2022combining} fused a classic disease regression (which provided interpretability) with machine learning (which provided flexibility to use mobility flows and contact network data) This multimodal model achieved the lowest error in a benchmark and highlighted that including mobility and colocation data is crucial to capture infection spread patterns. Beyond regional forecasting, others have integrated medical knowledge at the individual level For instance, \citet{zhiweidingBiologyInformedRecurrentNeural2023} developed a biology-informed RNN that incorporates viral dynamics and immune response models to predict individual patient trajectories proposed a biology-informed RNN where they incorporate the log-normal distributed incubation period into an LSTM architecture By using multimodal inputs (e.g. case counts and human mobility) and a “back-projection” Susceptible-Infected framework, their model (BPISI-LSTM) could predict both confirmed and true infections, outperforming baseline LSTMs


As the field matures, researchers are exploring architectures that unify spatial and temporal modeling more deeply. One direction has been to combine GNNs with Transformer-style sequence models. \citet{han2025dygraphformer} proposed DyGraphFormer, which integrates dynamic graph learning with a Transformer to capture evolving spatial-temporal dependencies for COVID-19 forecasting. a dynamic graph Transformer for multivariate time series forecasting In DyGraphformer, the self-attention layers (excellent for long-term temporal dependencies) are augmented by a \textit{dynamic graph convolution} module that infers time-varying inter-series relationships Unlike earlier graph-based models with a fixed adjacency, DyGraphformer’s graph is continually updated using recent history (via a GRU that captures how spatial dependencies evolve) They also employ a hierarchical encoder to capture multi-scale patterns, and notably remove the standard Transformer decoder for efficiency This design led to superior accuracy on several real-world datasets compared to static-graph GNNs or vanilla Transformers Another cutting-edge model is the Dynamic Adaptive Spatio-Temporal Graph Network (DASTGN) proposed by \citet{pu2024dynamic} DASTGN explicitly tackles the “mixed” space–time relations in epidemics by using attention mechanisms to adaptively fuse spatial and temporal effects in a single framework It introduces a dual-scale attention approach: at a fine-grained level it separately models time-specific and space-specific propagation influences, and at a coarse-grained level it captures the impacts of various spatio-temporal neighbor “blocks” (e.g. regional clusters over a recent time window) under different intervention scenarios By combining these, DASTGN can represent complex dependencies that change over time and space. On three COVID-19 datasets, it achieved state-of-the-art results, with error reductions up to 17.1\% (RMSE) and 11.6\% (MAE) against previous models The learned attention weights in DASTGN’s modules were shown to reveal meaningful diffusion patterns (for example, identifying when inter-city interactions spike)

A practical challenge for deep spatiotemporal models is scalability, as fine-grained epidemic forecasting may involve hundreds of regions and long time series. Naively, a graph attention mechanism among $N$ locations incurs $O(N^2)$ computations, which becomes problematic for large $N$. Recent developments in efficient attention offer solutions. For instance, \citet{wang2020linformer} proposed Linformer, demonstrated that the self-attention in Transformers can be approximated by a low-rank matrix decomposition, reducing complexity from $O(n^2)$ to $O(n)$ without significant loss in accuracy This idea of \textit{linearized attention} – projecting the key and value matrices to a lower dimension – drastically cuts down memory and time usage for long sequences Such techniques are highly relevant for epidemic GNNs: for instance, applying linear attention within a graph context allows modeling interactions among many regions in linear time. Our MSAGAT-Net leverages this concept in its Efficient Adaptive Graph Attention Module, using a low-rank attention kernel to achieve linear complexity $O(N)$ for spatial attention. By doing so, it remains feasible to handle large-scale epidemics (e.g. nationwide county-level predictions) in real-time, which is critical for practical deployment. Overall, the landscape of deep learning for epidemic forecasting is moving towards models that are not only more accurate and interpretable, but also more efficient and scalable, capable of delivering timely insights for public health policy.

our work sits at the intersection of these developments. We focus exclusively on deep learning-based spatiotemporal epidemic forecasting, drawing inspiration from prior GNN architectures that capture cross-region transmission patterns \citep{dengColaGNNCrosslocationAttention2020a}, multi-scale temporal modeling techniques \citep{xie2022epignn}, and efficiency improvements like linear attention mechanisms \citep{wang2020linformer}. By integrating these elements into MSAGAT-Net – along with novel contributions such as progressive multi-step prediction and comprehensive ablation analysis – we aim to advance the state of the art in both accuracy and applicability of epidemic forecasts. 



% ---------- SECTION II: LITERATURE REVIEW ----------
\section{Related Work}

Traditional epidemiological forecasting has long relied upon compartmental models such as SIR and SEIR frameworks, alongside statistical time-series approaches. Whilst these methods provide interpretable mechanistic insights, they often struggle to capture the complex spatial interactions and non-linear temporal dynamics characteristic of real-world epidemic spread \cite{lijingwangCausalGNNCausalBasedGraph2022}. The emergence of deep learning, particularly graph neural networks (GNNs), has offered promising alternatives by naturally representing geographical regions as nodes and their interactions as edges, thereby enabling more flexible modelling of spatiotemporal dependencies.

\subsection{Graph Neural Networks for Epidemic Forecasting}

The application of GNNs to epidemic forecasting has gained considerable momentum in recent years. Cola-GNN, introduced by \citet{dengColaGNNCrosslocationAttention2020a}, pioneered the use of dynamic cross-location attention mechanisms for long-term influenza forecasting. Rather than relying on fixed geographical adjacency matrices, Cola-GNN learns adaptive attention weights between regions, effectively capturing time-varying influences. This approach demonstrated significant improvements in multi-week influenza-like illness (ILI) predictions whilst providing interpretable insights into inter-regional influences.

Building upon these foundations, \citet{xie2022epignn} developed EpiGNN, which incorporates transmission risk encoding and a Region-Aware Graph Learner to model both local and global spatial effects. EpiGNN's ability to integrate external data sources, such as human mobility patterns, enables regions to become contextually aware of neighbouring situations. The model achieved approximately 9.5\% improvement in RMSE over previous state-of-the-art methods across influenza and COVID-19 datasets.

Similarly, STAN (Spatio-Temporal Attention Network) by \citet{gao2021stan} employed attention-based graph convolution to capture dynamic geographical influences for COVID-19 forecasting. By incorporating patient electronic health record features and geography-based attention mechanisms, STAN demonstrated the ability to learn spatial-temporal trends across all US counties, achieving up to 87\% lower mean squared error compared to classical SIR/SEIR models.

\subsection{Temporal Modelling in Epidemic Forecasting}

The temporal dimension presents unique challenges in epidemic forecasting, particularly given the complex seasonality, trends, and behavioural change effects inherent in disease transmission. Deep learning models typically address multi-step forecasting through either direct methods (predicting multiple time steps simultaneously) or iterative approaches (sequential one-step predictions). Direct multi-horizon models, whilst capable of capturing long-term dependencies, often require substantial training data and may suffer from error accumulation in iterative strategies.

\citet{dengColaGNNCrosslocationAttention2020a} addressed long-term forecasting challenges by extracting multi-scale temporal features through dilated convolutions, finding that incorporating seasonal trends significantly improved forecast stability. Other researchers have explored hybrid approaches, with \citet{wu2018deep} investigating direct long-term neural predictors for influenza, whilst DEFSI by \citet{wang2019defsi} combined deep learning with compartmental models to enhance long-range forecasting capabilities.

The importance of capturing both short-term outbreak patterns and long-term epidemiological waves has led to the development of multi-module architectures. These approaches often leverage external data sources, including climatic conditions, demographic information, and digital trace data, to inform long-range forecasts and improve model robustness.

\subsection{Integration of Domain Knowledge}

Recent research has increasingly focused on integrating epidemiological domain knowledge into deep learning frameworks to enhance both interpretability and performance. CausalGNN by \citet{lijingwangCausalGNNCausalBasedGraph2022} exemplifies this approach by combining mechanistic ODE-based disease models with dynamic GNNs. The attention-based GNN module captures cross-region influences whilst a causal module based on SIR-type ordinary differential equations injects epidemiological context into node embeddings.

MepoGNN by \citet{cao2022mepognn} employs a multi-patch SEIR model within a metapopulation GNN framework. This approach merges region-level compartmental models with Graph Attention Networks that process real-world mobility and case data, transforming static travel matrices into dynamic transmission adjacency matrices. The model successfully predicted COVID-19 spread in South Korea, with learned transmission rates aligning well with policy interventions such as social distancing measures.

\subsection{Scalability and Efficiency Considerations}

A significant challenge in deploying spatiotemporal models for epidemic forecasting is computational scalability, particularly when dealing with fine-grained geographical resolutions involving hundreds of regions and extended time series. Traditional graph attention mechanisms incur O(N²) computational complexity, becoming prohibitive for large-scale applications.

Recent advances in efficient attention mechanisms offer potential solutions. The concept of linearised attention, demonstrated by \citet{wang2020linformer}, shows that self-attention in Transformers can be approximated through low-rank matrix decomposition, reducing complexity from O(n²) to O(n) without substantial accuracy loss. This technique proves particularly relevant for epidemic GNNs, enabling the modelling of interactions among numerous regions in linear time.

Our proposed MSAGAT-Net leverages these efficiency improvements whilst addressing the multi-scale temporal modelling requirements and progressive prediction challenges identified in the literature. By combining linearised attention mechanisms with adaptive graph learning and multi-scale temporal processing, we aim to advance both the accuracy and practical applicability of epidemic forecasting systems.


\begin{abstract}
We present MSAGAT-Net, a novel Multi-Scale Temporal Graph Attention Network designed for accurate spatiotemporal epidemic forecasting across multiple geographical regions. Our approach addresses three critical challenges in epidemic prediction: (1) capturing complex spatial dependencies between regions with linear-time complexity, (2) modeling multi-scale temporal patterns in disease transmission, and (3) generating reliable multi-horizon forecasts. MSAGAT-Net introduces three key innovations: an Efficient Adaptive Graph Attention Module (EAGAM) that achieves O(N) complexity through linearized attention mechanisms and low-rank decomposition, a Dilated Multi-Scale Temporal Module (DMTM) that captures both short-term fluctuations and long-term trends, and a Progressive Prediction Module (PPM) for iterative multi-step forecasting. Through extensive experiments on diverse epidemic datasets spanning influenza and COVID-19 across multiple countries, MSAGAT-Net consistently outperforms state-of-the-art methods, achieving up to 23.7\% lower RMSE and 15.8\% higher correlation coefficients. Our ablation studies reveal disease-specific and horizon-dependent component importance patterns, providing insights into the varying spatiotemporal dynamics of different epidemics. The model's efficiency and interpretability make it particularly suitable for real-time public health surveillance and decision support systems.
\end{abstract}

\begin{abstract}
Spatiotemporal epidemic forecasting is critical for public health decision-making, yet existing approaches face challenges in computational scalability and multi-scale temporal modeling. We present MSAGAT-Net, a Multi-Scale Temporal Graph Attention Network that integrates four key components: efficient feature extraction through depthwise separable convolutions, an Efficient Adaptive Graph Attention Module (EAGAM) achieving O(N) complexity via Linformer-inspired low-rank decomposition, a Multi-Scale Temporal Feature Module (MTFM) capturing dynamics across multiple time resolutions using dilated convolutions, and a Progressive Prediction Refinement Module (PPRM) for stable multi-horizon forecasting. Extensive experiments on seven epidemic datasets spanning influenza and COVID-19 demonstrate consistent superiority over state-of-the-art methods, with up to 28.94\% RMSE improvement and 22.19\% correlation enhancement. Ablation studies reveal disease-specific patterns in component importance, highlighting the model's adaptability across different epidemic contexts. The linear computational complexity enables real-time deployment for large-scale epidemic surveillance.
\end{abstract}

Accurate and scalable spatiotemporal epidemic forecasting remains challenging due to computational costs and multi-scale temporal dynamics. We present MSAGAT-Net, a compact Multi-Scale Temporal Graph Attention Network with: (i) efficient feature extraction via depthwise separable convolutions; (ii) an Efficient Adaptive Graph Attention Module (EAGAM) with linear O(N) complexity and interpretable inter-regional dependencies; (iii) a Dilated Multi-Scale Temporal Feature Module (DMTFM) for multi-resolution dynamics; and (iv) a Progressive Prediction Refinement Module (PPRM) for stable multi-step forecasts. Across seven datasets (influenza and COVID-19), MSAGAT-Net outperforms strong baselines (DCRNN, LSTNet, CNNRNN-Res, Cola-GNN, EpiGNN), achieving up to 11.2\% lower RMSE on Japan‑Prefectures (3/10/15‑day) and leading short‑horizon results on LTLA. Ablations show horizon- and disease-specific utility of each component. With linear complexity and interpretable attention, MSAGAT‑Net is practical for real‑time surveillance and decision support.


% ---------- SECTION II: LITERATURE REVIEW ----------
\section{Related Work}

Epidemiological forecasting has progressed from classical compartmental models (e.g., SIR/SEIR) to data-driven neural approaches. Whilst mechanistic models provide valuable theoretical insight, they often struggle with the non-linear, spatially mediated dynamics seen in practice \cite{lijingwangCausalGNNCausalBasedGraph2022}. Graph neural networks (GNNs) have therefore become prominent, as they naturally represent regions as nodes and interactions as edges.

The GNN literature for epidemics can be viewed in complementary strands. First, pure neural spatiotemporal models learn data-driven dependencies without mechanistic priors. Cola-GNN \cite{dengColaGNNCrosslocationAttention2020a} introduced cross-location attention that adapts spatial influence over time, coupled with dilated convolutions to capture short- and long-range temporal patterns, improving multi-week influenza forecasting while enhancing interpretability. EpiGNN \cite{xie2022epignn} embeds transmission risk encoding and a Region-Aware Graph Learner to model local and global effects, reporting roughly a 9.5\% RMSE reduction across influenza and COVID-19 settings. STAN \cite{gao2021stan} applies attention-based graph convolution to COVID-19, incorporating electronic health record and geographical context; it reports notable gains over SIR/SEIR baselines and includes physics-inspired regularisation to stabilise long-range forecasts.

Second, forecasting strategy matters. Direct multi-horizon predictors (sequence-to-sequence with LSTM/CNN) avoid error accumulation but can require substantial data and exogenous covariates; iterative predictors are data-efficient yet prone to compounding error. Prior work explores both directions: direct long-term neural predictors \cite{wu2018deep, venna2019novel} and hybrid approaches like DEFSI \cite{wang2019defsi}, which couples deep learning with compartmental structure to improve long-range performance. Cola-GNN also evidenced the value of multi-scale temporal features via dilated convolutions for stable long-term forecasting \cite{dengColaGNNCrosslocationAttention2020a}.

Third, hybrid and physics-informed designs integrate domain structure for robustness and interpretability. CausalGNN \cite{lijingwangCausalGNNCausalBasedGraph2022} combines ODE-based disease dynamics with attention-driven spatial learning. MepoGNN \cite{cao2022mepognn} embeds a multi-patch SEIR within a metapopulation GNN using real mobility and case data. HOIST \cite{gao2023evidence} regularises learning via an Ising-inspired prior to encode spatial correlation principles, yielding policy-relevant insights at national scale.

Fourth, dynamic/adaptive graph learning captures evolving connectivity. DyGraphFormer \cite{han2025dygraphformer} unifies Transformers with dynamic graphs updated from recent history, while DASTGN \cite{pu2024dynamic} uses dual-scale attention to disentangle fine- and coarse-grained spatio-temporal influences under shifting interventions.

Finally, scalability is a practical constraint for fine-grained regional forecasting. Conventional attention over $N$ regions incurs $O(N^2)$ cost, limiting real-time utility. Efficient attention mechanisms, particularly Linformer (Wang et al., 2020) \cite{wang2020linformer}, achieve approximately $O(N)$ complexity via low-rank projections, offering a route to tractable inference at scale.

In summary, prior work demonstrates: (i) adaptive spatial learning improves accuracy and interpretability; (ii) multi-scale temporal processing stabilises longer horizons; and (iii) efficient attention is essential for large $N$. However, few methods combine all three in a compact architecture whilst explicitly addressing multi-horizon stability. MSAGAT-Net is designed to fill this gap through EAGAM (efficient, interpretable adaptive attention), DMTFM (dilated multi-scale temporal processing), and PPRM (progressive, horizon-aware refinement), yielding a practical and scalable framework for epidemic forecasting.


% ---------- SECTION II: LITERATURE REVIEW ----------
\section{Related Work}

Epidemiological forecasting has evolved considerably from traditional compartmental models such as SIR and SEIR, which, whilst providing valuable theoretical insights, often struggle to capture the complex spatial interactions and non-linear dynamics characteristic of real-world disease transmission \cite{lijingwangCausalGNNCausalBasedGraph2022}. The emergence of deep learning approaches has transformed this landscape, with graph neural networks proving particularly effective for modelling disease spread across interconnected regions by naturally representing locations as nodes and their interactions as edges.

The application of graph neural networks to epidemic forecasting addresses fundamental limitations of traditional approaches by learning complex spatiotemporal relationships directly from data. A comprehensive review by Liu et al. \cite{liuReviewGraphNeural2024a, wang_deepest_2024} categorises these methods into pure neural versus hybrid mechanistic-neural models, highlighting their growing significance in epidemiological research.

Deng et al. \cite{dengColaGNNCrosslocationAttention2020a} pioneered the use of dynamic cross-location attention mechanisms in their Cola-GNN framework for long-term influenza forecasting. Rather than relying on fixed geographic adjacency matrices, Cola-GNN learns adaptive attention weights between regions, effectively creating a dynamic graph that captures time-varying influences. This attention mechanism is coupled with dilated convolutional neural networks for temporal feature extraction, enabling the model to capture both short-term fluctuations and long-term patterns. The resulting framework not only improved multi-week ILI predictions but also provided interpretable insights into inter-regional influences.

Building upon these foundations, Xie et al. \cite{xie2022epignn} developed EpiGNN, which incorporates transmission risk encoding and a Region-Aware Graph Learner to model both local and global spatial effects. EpiGNN's architecture allows for the integration of external data sources, such as human mobility patterns, into the graph learning process. This approach demonstrated substantial improvements over previous state-of-the-art methods, achieving approximately 9.5\% reduction in RMSE across influenza and COVID-19 datasets.

Similarly, Gao et al. \cite{gao2021stan} proposed STAN (Spatio-Temporal Attention Network), which leverages attention-based graph convolution to capture dynamic geographical influences for COVID-19 forecasting. By incorporating patient electronic health record features and geography-based attention mechanisms, STAN successfully modelled spatial-temporal trends across all U.S. counties, significantly outperforming classical SIR/SEIR models with up to 87\% lower mean squared error. Notably, STAN incorporated physics-based regularisation terms derived from compartmental dynamics to improve long-range forecast stability.

The temporal dimension of epidemic forecasting presents unique challenges, as epidemic time series often exhibit complex seasonality, trends, and behavioural change effects. Current approaches to multi-step forecasting can be broadly categorised into direct methods, which predict multiple time steps simultaneously, and iterative methods, which generate forecasts sequentially.

Direct multi-horizon models, often implemented using sequence-to-sequence architectures with LSTM or CNN components, have demonstrated effectiveness in influenza forecasting but typically require substantial training data and may depend heavily on external covariates. Conversely, iterative strategies, whilst more data-efficient, suffer from error accumulation over extended forecasting horizons.

Deng et al. \cite{dengColaGNNCrosslocationAttention2020a} addressed long-term forecasting challenges by extracting multi-scale temporal features through dilated convolutions, finding that incorporating seasonal trends significantly improved forecast stability. Other researchers have explored hybrid approaches: Wu et al. \cite{wu2018deep} and Venna et al. \cite{venna2019novel} investigated direct long-term neural predictors for influenza, whilst Wang et al. \cite{wang2019defsi} developed DEFSI, which combines deep learning with compartmental models to enhance long-range forecasts.

The recognition of both short-term outbreaks and long-term epidemiological waves has led to the development of multi-module architectures that can simultaneously capture high-frequency fluctuations and low-frequency trends. These approaches often incorporate external data sources, including climate variables, demographic information, and digital surveillance indicators, to inform long-range predictions.

A particularly promising research direction involves the integration of epidemiological domain knowledge into deep learning frameworks to improve both interpretability and performance. Wang et al. \cite{lijingwangCausalGNNCausalBasedGraph2022} developed CausalGNN, which combines mechanistic ODE-based disease models with dynamic graph neural networks. In CausalGNN, an attention-based graph module captures cross-regional influences whilst a causal module, grounded in SIR-type ordinary differential equations, injects epidemiological context into node embeddings. This mutually-informed design yields more robust predictions with reduced parameter requirements.

Cao et al. \cite{cao2022mepognn} proposed MepoGNN, employing a multi-patch SEIR model within a metapopulation graph neural network framework. This approach merges region-level compartmental simulators with a Graph Attention Network that processes real-world mobility and case data, transforming static travel matrices into dynamic transmission adjacency matrices. When applied to COVID-19 spread in South Korea, MepoGNN demonstrated superior performance compared to pure simulation models, with learned transmission rates closely aligning with actual policy interventions.

Gao et al. \cite{gao2023evidence} took a physics-inspired approach with their HOIST model, drawing analogies between disease spread and Ising spin systems. By treating counties as nodes on a lattice and using Ising dynamics to regularise deep forecasting models, they encoded the principle that neighbouring regions' case counts should evolve in correlated patterns. Applied to 2,299 U.S. counties for four-week COVID-19 hospitalisation forecasting, HOIST achieved strong performance whilst providing policy-relevant insights, such as identifying rural vaccination strategies as particularly effective interventions.

Recent developments have focused on architectures that unify spatial and temporal modelling more deeply. Han et al. \cite{han2025dygraphformer} developed DyGraphFormer, integrating dynamic graph learning with Transformer architectures to capture evolving spatial-temporal dependencies. Unlike earlier models with fixed adjacency matrices, DyGraphFormer continuously updates its graph structure using recent historical data through gated recurrent units, allowing for adaptive representation of changing spatial dependencies.

Pu et al. \cite{pu2024dynamic} proposed the Dynamic Adaptive Spatio-Temporal Graph Network (DASTGN), which explicitly addresses mixed space-time relationships in epidemics through attention mechanisms that adaptively fuse spatial and temporal effects. DASTGN employs dual-scale attention: fine-grained modelling of time-specific and space-specific propagation influences, and coarse-grained capture of spatio-temporal neighbourhood blocks under varying intervention scenarios.

A critical practical consideration for large-scale epidemic forecasting is computational scalability. Traditional graph attention mechanisms among $N$ locations incur $O(N^2)$ computational complexity, which becomes prohibitive for fine-grained regional analysis. Recent advances in efficient attention, particularly linearised attention mechanisms that achieve $O(N)$ complexity through low-rank matrix decomposition called linformer by Wang et al. \cite{wang2020linformer}, offer promising solutions for real-time epidemic surveillance applications.


Despite these advances, several challenges remain in spatiotemporal epidemic forecasting. Current models often struggle to balance computational efficiency with modelling capacity, particularly when scaling to large numbers of regions. Many approaches fail to adequately capture multi-scale temporal dynamics, where both immediate fluctuations and long-term trends influence disease transmission. Additionally, most existing methods do not provide stable multi-horizon forecasting capabilities, which are essential for public health planning and resource allocation.

Our work addresses these gaps by developing MSAGAT-Net, which integrates efficient graph attention mechanisms, multi-scale temporal processing, and progressive prediction strategies. By combining insights from recent advances in linearised attention, adaptive graph learning, and multi-scale feature extraction, we aim to create a framework that maintains high accuracy whilst remaining computationally tractable for real-time deployment in public health surveillance systems.