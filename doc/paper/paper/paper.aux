\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ajao2023deep,da2021covid,giuliani2020modelling,verma2022temporal,ma2024reporting}
\citation{Panja2022Epicasting,Stone2007Seasonal}
\citation{heltberg2022spatial,s25082507,DEANGELIS201583}
\citation{li2017diffusion,zhang2021graph}
\citation{wu2018deep,lai2018modeling}
\citation{kimForecastingEpidemicSpread2025,zhiweidingBiologyInformedRecurrentNeural2023}
\citation{ajao2023deep,zhang2021graph,wu2018deep,lai2018modeling,Ahmadini2025}
\citation{Kamalov2022ReviewDL,wang2019defsi}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\citation{lijingwangCausalGNNCausalBasedGraph2022}
\citation{liuReviewGraphNeural2024a,wang_deepest_2024}
\citation{dengColaGNNCrosslocationAttention2020a}
\citation{xie2022epignn}
\citation{gao2021stan}
\citation{han2025dygraphformer}
\citation{pu2024dynamic}
\citation{cao2022mepognn}
\citation{gao2023evidence}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Spatiotemporal Epidemic Modelling}{2}{subsection.2.1}\protected@file@percent }
\citation{wang2020linformer}
\citation{Brooks2018Nonmechanistic}
\citation{Panja2022Epicasting}
\citation{Stone2007Seasonal}
\citation{Brooks2018Nonmechanistic}
\citation{wu2018deep,venna2019novel}
\citation{wang2019defsi}
\citation{dengColaGNNCrosslocationAttention2020a}
\citation{Luo2023Interpretable,Moss_Zarebski_Dawson_Franklin_Birrell_McCaw_2020}
\citation{Panja2022Epicasting}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Multi-Scale Temporal Modelling and Multi-Horizon Forecasting}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Problem Formulation}{3}{subsection.3.1}\protected@file@percent }
\citation{chollet2017xception}
\citation{li2023multi}
\citation{yu2022traffic}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Feature Extraction}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}1}Depthwise Separable Convolutions}{4}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}2}Low-Rank Feature Projection}{4}{subsubsection.3.2.2}\protected@file@percent }
\citation{velickovic2017graph}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the MSAGAT-Net architecture. The model processes input through four main modules: Feature Extraction (depthwise separable convolutions), AGAM, MTFM (dilation rates $d \in \{1,2,4\}$), and PPRM. The dashed line represents the skip connection for refinement.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:msagat_net_architecture}{{1}{5}{Overview of the MSAGAT-Net architecture. The model processes input through four main modules: Feature Extraction (depthwise separable convolutions), AGAM, MTFM (dilation rates $d \in \{1,2,4\}$), and PPRM. The dashed line represents the skip connection for refinement}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Efficient Adaptive Graph Attention with Low-Rank Decomposition}{5}{subsection.3.3}\protected@file@percent }
\citation{puny2020global}
\citation{kong2023low}
\citation{yang2023self}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Feature‑extraction pipeline. Independent regional time‑series $\mathbf  {x}^i$ and $\mathbf  {x}^j$ are processed in parallel by depth‑wise and point‑wise convolutions, normalised, flattened, passed through a bottleneck projection ($d_b\!\to \! d_h$), and normalised again to yield region‑level feature vectors $\mathbf  F$.}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:feature_extraction}{{2}{6}{Feature‑extraction pipeline. Independent regional time‑series $\mathbf {x}^i$ and $\mathbf {x}^j$ are processed in parallel by depth‑wise and point‑wise convolutions, normalised, flattened, passed through a bottleneck projection ($d_b\!\to \! d_h$), and normalised again to yield region‑level feature vectors $\mathbf F$}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Bottleneck Projection}{6}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Multi-Head Attention Mechanism}{7}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}3}Learnable Graph Structure}{7}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}4}Graph Bias Message Passing}{7}{subsubsection.3.3.4}\protected@file@percent }
\citation{Stone2007Seasonal,Panja2022Epicasting,Qiu2024MSGNN}
\citation{dengColaGNNCrosslocationAttention2020a}
\citation{xie2022epignn}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}5}Attention Regularisation}{8}{subsubsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Multi-Scale Temporal Feature Module}{8}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-D}1}Dilated Convolutions for Multi-scale Processing}{8}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Data flow in the AGAM module. Input features undergo low-rank QKV projections, followed by linearised attention computation. The learnable graph bias is integrated via normalised message passing, and L1 regularisation promotes sparse spatial patterns.}}{9}{figure.3}\protected@file@percent }
\newlabel{fig:agam_module}{{3}{9}{Data flow in the AGAM module. Input features undergo low-rank QKV projections, followed by linearised attention computation. The learnable graph bias is integrated via normalised message passing, and L1 regularisation promotes sparse spatial patterns}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-D}2}Adaptive Scale Fusion}{9}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-D}3}Bottleneck Projection and Residual Connection}{9}{subsubsection.3.4.3}\protected@file@percent }
\citation{BENTAIEB20127067,chandra2021evaluation}
\citation{hochreiter1997long}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Data flow in the MTFM module. Spatial features from AGAM are processed through three parallel dilated convolutional branches (dilation rates 1, 2, 4), adaptively fused using learnable weights, and combined with residual connections.}}{10}{figure.4}\protected@file@percent }
\newlabel{fig:mtfm_module}{{4}{10}{Data flow in the MTFM module. Spatial features from AGAM are processed through three parallel dilated convolutional branches (dilation rates 1, 2, 4), adaptively fused using learnable weights, and combined with residual connections}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-E}}Progressive Multi-Horizon Forecast Refinement}{10}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-E}1}Low-Rank Forecast Projection}{11}{subsubsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-E}2}Horizon-Specific Prediction}{11}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-E}3}Adaptive Refinement Mechanism}{11}{subsubsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Setup}{11}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{IV}{11}{Experimental Setup}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Computing Environment}{11}{subsection.4.1}\protected@file@percent }
\newlabel{sec:experimental_setup}{{\mbox  {IV-A}}{11}{Computing Environment}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Data flow in the PPRM module. Features are projected through a low-rank bottleneck to generate initial predictions. An adaptive gate learns to balance these model-based forecasts with exponential trend extrapolations based on recent observations.}}{12}{figure.5}\protected@file@percent }
\newlabel{fig:pprm_module}{{5}{12}{Data flow in the PPRM module. Features are projected through a low-rank bottleneck to generate initial predictions. An adaptive gate learns to balance these model-based forecasts with exponential trend extrapolations based on recent observations}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Datasets}{12}{subsection.4.2}\protected@file@percent }
\newlabel{sec:datasets}{{\mbox  {IV-B}}{12}{Datasets}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Overview of the epidemic datasets used in our experimental evaluation. ``Granularity'' indicates the temporal resolution of the epidemic data, whilst ``Size'' represents the product of the number of locations and the number of time steps.}}{12}{table.1}\protected@file@percent }
\newlabel{tab:datasets}{{I}{12}{Overview of the epidemic datasets used in our experimental evaluation. ``Granularity'' indicates the temporal resolution of the epidemic data, whilst ``Size'' represents the product of the number of locations and the number of time steps}{table.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-B}1}Influenza Datasets}{12}{subsubsection.4.2.1}\protected@file@percent }
\citation{NHS2024HospitalActivity}
\citation{gao2021stan}
\citation{ajao2023deep,oluwasakin2023data,zeroual2020deep,Kamalov2022ReviewDL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {IV-B}2}COVID-19 Datasets}{13}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Graph Construction Methodology}{13}{subsection.4.3}\protected@file@percent }
\newlabel{sec:graph_construction}{{\mbox  {IV-C}}{13}{Graph Construction Methodology}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Model Optimisation}{13}{subsection.4.4}\protected@file@percent }
\newlabel{sec:optimisation}{{\mbox  {IV-D}}{13}{Model Optimisation}{subsection.4.4}{}}
\citation{li2017diffusion}
\citation{lai2018modeling}
\citation{wu2018deep}
\citation{dengColaGNNCrosslocationAttention2020a}
\citation{xie2022epignn}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces MSAGAT-Net Training Algorithm}}{14}{algocf.1}\protected@file@percent }
\newlabel{alg:MSAGAT-Net_training}{{1}{14}{Model Optimisation}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-E}}Baseline Models}{14}{subsection.4.5}\protected@file@percent }
\newlabel{sec:baseline_models}{{\mbox  {IV-E}}{14}{Baseline Models}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Discussion}{14}{section.5}\protected@file@percent }
\newlabel{sec:results}{{V}{14}{Results and Discussion}{section.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces RMSE and PCC performance of different methods on three datasets (horizon = 3, 5, 10, 15). Bold = best, underline = second best.}}{15}{table.2}\protected@file@percent }
\newlabel{tab:performance_table}{{II}{15}{RMSE and PCC performance of different methods on three datasets (horizon = 3, 5, 10, 15). Bold = best, underline = second best}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces RMSE performance of different methods on four datasets (horizon = 3, 7, 14). Bold = best, underline = second best.}}{15}{table.3}\protected@file@percent }
\newlabel{tab:performance_table_others}{{III}{15}{RMSE performance of different methods on four datasets (horizon = 3, 7, 14). Bold = best, underline = second best}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Ablation Study}{16}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Attention matrices learned by MSAGAT-Net on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right).}}{17}{figure.6}\protected@file@percent }
\newlabel{fig:attention_matrices_none}{{6}{17}{Attention matrices learned by MSAGAT-Net on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right)}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Attention matrices learned by MSAGAT-Net without PPRM on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right).}}{17}{figure.7}\protected@file@percent }
\newlabel{fig:attention_matrices_no_pprm}{{7}{17}{Attention matrices learned by MSAGAT-Net without PPRM on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right)}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Attention matrices learned by MSAGAT-Net without AGAM on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right).}}{17}{figure.8}\protected@file@percent }
\newlabel{fig:attention_matrices_no_agam}{{8}{17}{Attention matrices learned by MSAGAT-Net without AGAM on the Japan-Prefectures dataset for 5-day forecasting: adjacency matrix (left), input correlation (center), and learned attention (right)}{figure.8}{}}
\newlabel{fig:ablation:rmse_h3}{{9a}{18}{Subfigure 9a}{subfigure.9.1}{}}
\newlabel{sub@fig:ablation:rmse_h3}{{(a)}{a}{Subfigure 9a\relax }{subfigure.9.1}{}}
\newlabel{fig:ablation:rmse_h5}{{9b}{18}{Subfigure 9b}{subfigure.9.2}{}}
\newlabel{sub@fig:ablation:rmse_h5}{{(b)}{b}{Subfigure 9b\relax }{subfigure.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Ablation study results for RMSE on the Japan-Prefectures dataset for short-term horizons (3-day and 5-day forecasts).}}{18}{figure.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {3-day Horizon RMSE}}}{18}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {5-day Horizon RMSE}}}{18}{subfigure.9.2}\protected@file@percent }
\newlabel{fig:ablation:rmse}{{9}{18}{Ablation study results for RMSE on the Japan-Prefectures dataset for short-term horizons (3-day and 5-day forecasts)}{figure.9}{}}
\newlabel{fig:ablation:rmse_h10}{{10a}{18}{Subfigure 10a}{subfigure.10.1}{}}
\newlabel{sub@fig:ablation:rmse_h10}{{(a)}{a}{Subfigure 10a\relax }{subfigure.10.1}{}}
\newlabel{fig:ablation:rmse_h15}{{10b}{18}{Subfigure 10b}{subfigure.10.2}{}}
\newlabel{sub@fig:ablation:rmse_h15}{{(b)}{b}{Subfigure 10b\relax }{subfigure.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Ablation study results for RMSE on the Japan-Prefectures dataset for long-term horizons (10-day and 15-day forecasts).}}{18}{figure.10}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {10-day Horizon RMSE}}}{18}{subfigure.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {15-day Horizon RMSE}}}{18}{subfigure.10.2}\protected@file@percent }
\newlabel{fig:ablation:rmse_long}{{10}{18}{Ablation study results for RMSE on the Japan-Prefectures dataset for long-term horizons (10-day and 15-day forecasts)}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Ablation study results on the Japan-Prefectures dataset, showing the impact of removing key components of MSAGAT-Net on forecasting performance across different horizons.}}{18}{table.4}\protected@file@percent }
\newlabel{tab:ablation}{{IV}{18}{Ablation study results on the Japan-Prefectures dataset, showing the impact of removing key components of MSAGAT-Net on forecasting performance across different horizons}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Ablation study results on LTLA-Timeseries dataset (COVID-19) with window size 20 across different forecast horizons. Values in parentheses indicate percentage change relative to the full model.}}{19}{table.5}\protected@file@percent }
\newlabel{tab:ablation_ltla}{{V}{19}{Ablation study results on LTLA-Timeseries dataset (COVID-19) with window size 20 across different forecast horizons. Values in parentheses indicate percentage change relative to the full model}{table.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{19}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{VI}{19}{Conclusion}{section.6}{}}
\newlabel{fig:component_impact_japan_h3}{{11a}{20}{Subfigure 11a}{subfigure.11.1}{}}
\newlabel{sub@fig:component_impact_japan_h3}{{(a)}{a}{Subfigure 11a\relax }{subfigure.11.1}{}}
\newlabel{fig:component_impact_japan_h5}{{11b}{20}{Subfigure 11b}{subfigure.11.2}{}}
\newlabel{sub@fig:component_impact_japan_h5}{{(b)}{b}{Subfigure 11b\relax }{subfigure.11.2}{}}
\newlabel{fig:component_impact_japan_h10}{{11c}{20}{Subfigure 11c}{subfigure.11.3}{}}
\newlabel{sub@fig:component_impact_japan_h10}{{(c)}{c}{Subfigure 11c\relax }{subfigure.11.3}{}}
\newlabel{fig:component_impact_japan_h15}{{11d}{20}{Subfigure 11d}{subfigure.11.4}{}}
\newlabel{sub@fig:component_impact_japan_h15}{{(d)}{d}{Subfigure 11d\relax }{subfigure.11.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Component impact analysis across different forecast horizons for the Japan-Prefectures dataset, showing the relative contribution of each MSAGAT-Net module to overall forecasting performance.}}{20}{figure.11}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {3-day Horizon Component Impact}}}{20}{subfigure.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {5-day Horizon Component Impact}}}{20}{subfigure.11.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {10-day Horizon Component Impact}}}{20}{subfigure.11.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {15-day Horizon Component Impact}}}{20}{subfigure.11.4}\protected@file@percent }
\newlabel{fig:component_impact_japan}{{11}{20}{Component impact analysis across different forecast horizons for the Japan-Prefectures dataset, showing the relative contribution of each MSAGAT-Net module to overall forecasting performance}{figure.11}{}}
\bibstyle{IEEEtran}
\bibdata{ref}
\bibcite{ajao2023deep}{{1}{}{{}}{{}}}
\bibcite{da2021covid}{{2}{}{{}}{{}}}
\bibcite{giuliani2020modelling}{{3}{}{{}}{{}}}
\bibcite{verma2022temporal}{{4}{}{{}}{{}}}
\bibcite{ma2024reporting}{{5}{}{{}}{{}}}
\bibcite{Panja2022Epicasting}{{6}{}{{}}{{}}}
\bibcite{Stone2007Seasonal}{{7}{}{{}}{{}}}
\bibcite{heltberg2022spatial}{{8}{}{{}}{{}}}
\bibcite{s25082507}{{9}{}{{}}{{}}}
\bibcite{DEANGELIS201583}{{10}{}{{}}{{}}}
\bibcite{li2017diffusion}{{11}{}{{}}{{}}}
\bibcite{zhang2021graph}{{12}{}{{}}{{}}}
\bibcite{wu2018deep}{{13}{}{{}}{{}}}
\bibcite{lai2018modeling}{{14}{}{{}}{{}}}
\bibcite{kimForecastingEpidemicSpread2025}{{15}{}{{}}{{}}}
\bibcite{zhiweidingBiologyInformedRecurrentNeural2023}{{16}{}{{}}{{}}}
\bibcite{Ahmadini2025}{{17}{}{{}}{{}}}
\bibcite{Kamalov2022ReviewDL}{{18}{}{{}}{{}}}
\bibcite{wang2019defsi}{{19}{}{{}}{{}}}
\bibcite{lijingwangCausalGNNCausalBasedGraph2022}{{20}{}{{}}{{}}}
\bibcite{liuReviewGraphNeural2024a}{{21}{}{{}}{{}}}
\bibcite{wang_deepest_2024}{{22}{}{{}}{{}}}
\bibcite{dengColaGNNCrosslocationAttention2020a}{{23}{}{{}}{{}}}
\bibcite{xie2022epignn}{{24}{}{{}}{{}}}
\bibcite{gao2021stan}{{25}{}{{}}{{}}}
\bibcite{han2025dygraphformer}{{26}{}{{}}{{}}}
\bibcite{pu2024dynamic}{{27}{}{{}}{{}}}
\bibcite{cao2022mepognn}{{28}{}{{}}{{}}}
\bibcite{gao2023evidence}{{29}{}{{}}{{}}}
\bibcite{wang2020linformer}{{30}{}{{}}{{}}}
\bibcite{Brooks2018Nonmechanistic}{{31}{}{{}}{{}}}
\bibcite{venna2019novel}{{32}{}{{}}{{}}}
\bibcite{Luo2023Interpretable}{{33}{}{{}}{{}}}
\bibcite{Moss_Zarebski_Dawson_Franklin_Birrell_McCaw_2020}{{34}{}{{}}{{}}}
\bibcite{chollet2017xception}{{35}{}{{}}{{}}}
\bibcite{li2023multi}{{36}{}{{}}{{}}}
\bibcite{yu2022traffic}{{37}{}{{}}{{}}}
\bibcite{velickovic2017graph}{{38}{}{{}}{{}}}
\bibcite{puny2020global}{{39}{}{{}}{{}}}
\bibcite{kong2023low}{{40}{}{{}}{{}}}
\bibcite{yang2023self}{{41}{}{{}}{{}}}
\bibcite{Qiu2024MSGNN}{{42}{}{{}}{{}}}
\bibcite{BENTAIEB20127067}{{43}{}{{}}{{}}}
\bibcite{chandra2021evaluation}{{44}{}{{}}{{}}}
\bibcite{hochreiter1997long}{{45}{}{{}}{{}}}
\bibcite{NHS2024HospitalActivity}{{46}{}{{}}{{}}}
\bibcite{oluwasakin2023data}{{47}{}{{}}{{}}}
\bibcite{zeroual2020deep}{{48}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{23}
